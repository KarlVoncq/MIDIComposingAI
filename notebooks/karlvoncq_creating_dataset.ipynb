{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d236046a-6871-40a7-bbfa-8e963608b574",
   "metadata": {},
   "source": [
    "# Creating the dataset for DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e63f841-e900-4860-8224-d0981bbe8569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-01 20:29:03.663181: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-01 20:29:03.663274: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pretty_midi\n",
    "import visual_midi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import getsize\n",
    "from MIDIComposingAI.utils import piano_roll_to_pretty_midi\n",
    "from MIDIComposingAI.create_csv_dataset import create_simple_dataset\n",
    "from scipy.sparse import csr_matrix\n",
    "from tensorflow import convert_to_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdc21240-49cd-4457-8f2b-4b65900d5915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_pitch_velocity(target):\n",
    "    \"\"\"\n",
    "    Separate pitch and velocity within the target\n",
    "    \"\"\"\n",
    "    # Lists of each velocities and pitches for each sample\n",
    "    sample_velocities = []\n",
    "    sample_pitches = []\n",
    "    \n",
    "    for sample in target:\n",
    "        # Lists of velocities and pitches within the sample\n",
    "        velocities = []\n",
    "        pitches = []\n",
    "        \n",
    "        for frame in sample.T:\n",
    "            frame = list(frame)\n",
    "            velocity = np.sum(frame)\n",
    "            velocities.append(velocity)\n",
    "            pitches.append(frame.index(velocity))\n",
    "        sample_velocities.append(velocities)\n",
    "        sample_pitches.append(pitches)\n",
    "    \n",
    "    return (sample_pitches, sample_velocities)\n",
    "\n",
    "def create_dataframe_file(file, name, dataset_type='matrix', store=True):\n",
    "    \"\"\"\n",
    "    Save a dataset within a directory\n",
    "    Args:\n",
    "        file: a pretty_midi file\n",
    "    \"\"\"\n",
    "    # First we create a dataset\n",
    "    X, y = create_simple_dataset(file)\n",
    "    \n",
    "    # We create an empty dataframe\n",
    "    df = pd.DataFrame(columns=['accompaniment', 'melody_pitches', 'melody_velocities'])\n",
    "    \n",
    "    # We separate pitches and velocities from the melody\n",
    "    pitches, velocities = separate_pitch_velocity(y)\n",
    "    \n",
    "    if dataset_type == 'matrix':\n",
    "        # We add the feature, accompaniment\n",
    "        df['accompaniment'] = [csr_matrix(accompaniment) for accompaniment in X]\n",
    "        \n",
    "        # Then we add the two target to the dataframe\n",
    "        df['melody_pitches'] = [csr_matrix(pitch) for pitch in pitches]\n",
    "        df['melody_velocities'] = [csr_matrix(velocity) for velocity in velocities]\n",
    "    \n",
    "    if dataset_type == 'array':\n",
    "        # We add the feature, accompaniment\n",
    "        df['accompaniment'] = [accompaniment for accompaniment in X]\n",
    "        \n",
    "        # Then we add the two target to the dataframe\n",
    "        df['melody_pitches'] = [np.array(pitch) for pitch in pitches]\n",
    "        df['melody_velocities'] = [np.array(velocity) for velocity in velocities]\n",
    "        \n",
    "    # Then we store the data\n",
    "    if store:\n",
    "        joblib.dump(df, f'../raw_data/pandas_dataframes/simple_dataset/{name}')\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "    # We have to delete the local variables in order to make loops without overloading the RAM\n",
    "    del([X, y, pitches, velocities, df])\n",
    "\n",
    "def create_nparray_dataset(file, directory ,name, store=True):\n",
    "    \"\"\"\n",
    "    Create a nparray dataset\n",
    "    \"\"\"\n",
    "    X, y = create_simple_dataset(file)\n",
    "    \n",
    "    pitches, velocities = separate_pitch_velocity(y)\n",
    "    \n",
    "    X_accompaniment = np.array([accompaniment.T for accompaniment in X])\n",
    "        \n",
    "    # Then we add the two target to the dataframe/\n",
    "    y_pitch = np.array([np.array(pitch) for pitch in pitches])\n",
    "    y_velocity = np.array([np.array(velocity) for velocity in velocities])\n",
    "    \n",
    "    dataset = (X_accompaniment, y_pitch, y_velocity)\n",
    "    \n",
    "    if store:\n",
    "        joblib.dump(dataset, f'../raw_data/pandas_dataframes/{directory}/{name}')\n",
    "    else:\n",
    "        return dataset\n",
    "    del([X, y, pitches, velocities, X_accompaniment, y_pitch, y_velocity, dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76b2af7c-7646-434a-bd0e-df6caebcc4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's take some examples\n",
    "# examples_files = []\n",
    "# path = '../raw_data/pretty_midi'\n",
    "# directory = listdir(path)\n",
    "\n",
    "# for file in directory:\n",
    "#     if getsize(f'{path}/{file}') < 300000: # We don't want too big files\n",
    "#         examples_files.append(joblib.load(f'{path}/{file}'))\n",
    "#     if len(examples_files) >= 10:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "512357e1-ea5d-4678-9408-267dd3b56809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, file in enumerate(examples_files):\n",
    "#     create_nparray_dataset(file, f'nparray{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a65f60dd-add6-4a5c-8cfa-cb83ff361a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigger_examples_files = []\n",
    "path = '../raw_data/pretty_midi'\n",
    "directory = listdir(path)\n",
    "\n",
    "for file in directory:\n",
    "    if 100_000 < getsize(f'{path}/{file}') and getsize(f'{path}/{file}') < 200_000: # We don't want too big or too little files\n",
    "        bigger_examples_files.append(joblib.load(f'{path}/{file}'))\n",
    "    if len(bigger_examples_files) >= 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c414b213-97ff-478f-9926-cade9e37f14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterations over iterations ...\n",
    "for i in range(50):\n",
    "    create_nparray_dataset(bigger_examples_files[i], 'bigger_dataset', f'nparray{i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb777da0-09d2-4920-b58d-d171d3201c3d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Let's add another feature\n",
    "Is a note played ? (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21bbf2fa-c322-4933-a2b6-b74606b66cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = joblib.load('../raw_data/pandas_dataframes/bigger_dataset/nparray4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "198b3a1d-15e0-46e0-aaa5-64149bf1ca66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcfad8e6-0761-4f13-9911-b706e560343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_there_a_note(array):\n",
    "    \"\"\"\n",
    "    Return an array of 0 and 1, 0 when no note is played, 1 when a note is played\n",
    "    Args:\n",
    "        array : an array of dim 2\n",
    "    \"\"\"\n",
    "    \n",
    "    # We instanciate a flattened empty array from the input array's shape\n",
    "    output = np.zeros(array.shape).reshape(-1, 1)\n",
    "    \n",
    "    for i, note in enumerate(array.reshape(-1, 1)): # We want to iterate over all the array at once\n",
    "        if int(note[0]) != 0:\n",
    "            output[i][0] = 1\n",
    "    \n",
    "    return output.reshape(array.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
