{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f28eecc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pretty_midi\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from tensorflow.keras import models\n",
    "# from tensorflow.keras import layers\n",
    "# from keras_self_attention import SeqSelfAttention\n",
    "import os\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.multioutput import MultiOutputClassifier, MultiOutputRegressor\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b700e5f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Transform MIDI files to PrettyMIDI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa3047a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# targetPattern = r\"../raw_data/*/*/*/*/*.mid\"\n",
    "\n",
    "# midi_files_paths = glob.glob(targetPattern)\n",
    "\n",
    "# for file in midi_files_paths:\n",
    "#     try:\n",
    "#         joblib.dump(pretty_midi.PrettyMIDI(file), f'../raw_data/pretty_midi/{file.split(\"/\")[-1][:-4]}')\n",
    "        \n",
    "        \n",
    "#     except:\n",
    "        \n",
    "        \n",
    "#         pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51abf311",
   "metadata": {},
   "source": [
    "## Visualize PrettyMIDI files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eae055e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test on 1 random file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10941053",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "\n",
    "from visual_midi import Plotter\n",
    "from visual_midi import Preset\n",
    "from pretty_midi import PrettyMIDI\n",
    "\n",
    "pm = joblib.load('../raw_data/pretty_midi/Addicted')\n",
    "\n",
    "preset = Preset(plot_width=850)\n",
    "plotter = Plotter(preset) #, plot_max_length_bar=4\n",
    "\n",
    "plotter.show_notebook(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ebb196",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pm_piano = pm.get_piano_roll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69466d8",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "joblib.dump(pm, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a7c031",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test = joblib.load('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5cfb31",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c465c7",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "\n",
    "plotter.show_notebook(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c261ae",
   "metadata": {},
   "source": [
    "### Get PianoRoll to Pretty Midi function from Utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ed717a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/dianehb/code/KarlVoncq/MIDIComposingAI')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5202a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b73bffa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from MIDIComposingAI.utils import piano_roll_to_pretty_midi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54234de0",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Test Guitar Chords DataSet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63b352b",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Get Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817773bb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "guitar_chords_df = pd.read_csv('raw_data/guitar-chords-midi-pitches.csv', sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c53084c",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "guitar_chords_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9900ac0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "columns = guitar_chords_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abe88cf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "columns_to_transform = columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdd4315",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "columns_to_transform # Can't be transformed to integer yet because of NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8683245",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# NEED to DROP NA if the chords we use are shorter than 5th line.dropna()\n",
    "# In model user mask & padding with -1 for example ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90bb243",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Create MIDI test files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54f6119",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Create MIDI with first line\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaec1a5",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "guitar_chord_1_test = guitar_chords_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e73876",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "guitar_chord_1 = guitar_chord_1_test.values[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee9b957",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a PrettyMIDI object\n",
    "cello_c_chord = pretty_midi.PrettyMIDI()\n",
    "\n",
    "# Create an Instrument instance for a cello instrument\n",
    "\n",
    "cello_program = pretty_midi.instrument_name_to_program('Cello')\n",
    "\n",
    "\n",
    "cello = pretty_midi.Instrument(program=cello_program)\n",
    "\n",
    "# Iterate over notes\n",
    "for note_midi in guitar_chord_1:\n",
    "    \n",
    "    # Create a Note instance, starting at 0s and ending at .5s\n",
    "    note = pretty_midi.Note(velocity=100, pitch=int(note_midi), start=0, end=.5)\n",
    "    \n",
    "    # Add it to our cello instrument\n",
    "    \n",
    "    cello.notes.append(note)\n",
    "    \n",
    "# Add the cello instrument to the PrettyMIDI object\n",
    "\n",
    "cello_c_chord.instruments.append(cello)\n",
    "\n",
    "# Write out the MIDI data\n",
    "cello_c_chord.write('raw_data/guitar-am-chord.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c5b831",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Create MIDI with second line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1111c9d7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "guitar_chord_amaj_test = guitar_chords_df.iloc[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6984536a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "guitar_chord_amaj = guitar_chord_amaj_test.values[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44385ec7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a PrettyMIDI object\n",
    "cello_c_chord = pretty_midi.PrettyMIDI()\n",
    "\n",
    "# Create an Instrument instance for a cello instrument\n",
    "\n",
    "cello_program = pretty_midi.instrument_name_to_program('Cello')\n",
    "\n",
    "\n",
    "cello = pretty_midi.Instrument(program=cello_program)\n",
    "\n",
    "\n",
    "# Iterate over notes\n",
    "for note_midi in guitar_chord_amaj:\n",
    "    \n",
    "    # Create a Note instance, starting at 0s and ending at .5s\n",
    "    note = pretty_midi.Note(velocity=100, pitch=int(note_midi), start=0, end=.5)\n",
    "    \n",
    "    # Add it to our cello instrument\n",
    "    \n",
    "    cello.notes.append(note)\n",
    "    \n",
    "# Add the cello instrument to the PrettyMIDI object\n",
    "\n",
    "cello_c_chord.instruments.append(cello)\n",
    "\n",
    "# Write out the MIDI data\n",
    "cello_c_chord.write('raw_data/guitar-amaj-chord.mid')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f99eb67",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Create MIDI with A#m accord\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ddfa42",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "guitar_chord_adm_test = guitar_chords_df.iloc[62]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943d3f91",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "guitar_chord_adm = guitar_chord_adm_test.values[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29eee96",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a PrettyMIDI object\n",
    "cello_c_chord = pretty_midi.PrettyMIDI()\n",
    "\n",
    "# Create an Instrument instance for a cello instrument\n",
    "\n",
    "cello_program = pretty_midi.instrument_name_to_program('Cello')\n",
    "\n",
    "\n",
    "cello = pretty_midi.Instrument(program=cello_program)\n",
    "\n",
    "# Iterate over notes\n",
    "for note_midi in guitar_chord_adm:\n",
    "    \n",
    "    # Create a Note instance, starting at 0s and ending at .5s\n",
    "    note = pretty_midi.Note(velocity=100, pitch=int(note_midi), start=0, end=.5)\n",
    "    \n",
    "    # Add it to our cello instrument\n",
    "    \n",
    "    cello.notes.append(note)\n",
    "    \n",
    "# Add the cello instrument to the PrettyMIDI object\n",
    "\n",
    "cello_c_chord.instruments.append(cello)\n",
    "\n",
    "# Write out the MIDI data\n",
    "cello_c_chord.write('raw_data/guitar-adm-chord.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c57fc6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Create MIDI with last line\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272cddac",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "guitar_chord_2_test = guitar_chords_df.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f1deaf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "guitar_chord_2 = guitar_chord_2_test.values[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eadaa5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# TEST 2\n",
    "\n",
    "cello_c_chord = pretty_midi.PrettyMIDI()\n",
    "cello_program = pretty_midi.instrument_name_to_program('Cello')\n",
    "cello = pretty_midi.Instrument(program=cello_program)\n",
    "\n",
    "for note_midi in guitar_chord_2:\n",
    "    \n",
    "    note = pretty_midi.Note(velocity=100, pitch=int(note_midi), start=0, end=.5)\n",
    "    cello.notes.append(note)\n",
    "\n",
    "cello_c_chord.instruments.append(cello)\n",
    "\n",
    "# Write out the MIDI data\n",
    "cello_c_chord.write('raw_data/guitar-test2-chord.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f3c7be",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Test Music Scale Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa07b67c",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Get Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7576153d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "music_scale_df = pd.read_csv('raw_data/music-scales_with_columns.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4d7a99",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "music_scale_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735a3f6b",
   "metadata": {},
   "source": [
    "## Chords in a sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ae5129",
   "metadata": {},
   "source": [
    "### Chords Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3216b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chords_df = pd.read_csv('raw_data/chords_midi.csv', sep=\";\")\n",
    "#Dataset created manually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7525f3b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chord</th>\n",
       "      <th>Note1</th>\n",
       "      <th>Note2</th>\n",
       "      <th>Note3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_mineur</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C#_mineur</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D_mineur</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D#_mineur</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E_mineur</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Chord  Note1  Note2  Note3\n",
       "0   C_mineur      0      3      7\n",
       "1  C#_mineur      1      4      8\n",
       "2   D_mineur      2      5      9\n",
       "3  D#_mineur      3      6     10\n",
       "4   E_mineur      4      7     11"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chords_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c87a358",
   "metadata": {},
   "outputs": [],
   "source": [
    "chords_dict = chords_df.set_index('Chord').T.to_dict('list')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8236597d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C_mineur': [0, 3, 7],\n",
       " 'C#_mineur': [1, 4, 8],\n",
       " 'D_mineur': [2, 5, 9],\n",
       " 'D#_mineur': [3, 6, 10],\n",
       " 'E_mineur': [4, 7, 11],\n",
       " 'F_mineur': [5, 8, 0],\n",
       " 'F#_mineur': [6, 9, 1],\n",
       " 'G_mineur': [7, 10, 2],\n",
       " 'G#_mineur': [8, 11, 3],\n",
       " 'A_mineur': [9, 0, 4],\n",
       " 'A#_mineur': [10, 1, 5],\n",
       " 'B_mineur': [11, 2, 6],\n",
       " 'C_majeur': [0, 4, 7],\n",
       " 'C#_majeur': [1, 5, 8],\n",
       " 'D_majeur': [2, 6, 9],\n",
       " 'D#_majeur': [3, 7, 10],\n",
       " 'E_majeur': [4, 8, 11],\n",
       " 'F_majeur': [5, 9, 0],\n",
       " 'F#_majeur': [6, 10, 1],\n",
       " 'G_majeur': [7, 11, 2],\n",
       " 'G#_majeur': [8, 0, 3],\n",
       " 'A_majeur': [9, 1, 4],\n",
       " 'A#_majeur': [10, 2, 5],\n",
       " 'B_majeur': [11, 3, 6]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chords_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ac2bd5",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test on one sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84ae11b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b255ba96",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceac4f8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train[0][40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c6fdc7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_unique_pitches_one_oct(acc):\n",
    "#     pitches = []\n",
    "#     for instant in acc:\n",
    "#         for index, vel in enumerate(instant):\n",
    "#             if vel > 0:\n",
    "#                 pitches.append(index % 12)\n",
    "# Double list comprehension instead of the code above        \n",
    "    pitches = [index % 12 for instant in acc for index, vel in enumerate(instant) if vel > 0]\n",
    "     \n",
    "    return list(set(pitches))\n",
    "\n",
    "# [1, 2, 4, 6, 7, 9, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d782929a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for x in non_flat:\n",
    "#     if len(x) > 2\n",
    "#         for y in x:\n",
    "#             y\n",
    "            \n",
    "# [ y for x in non_flat if len(x) > 2 for y in x ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0740ebf3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # Explanation for double list comprehension on https://spapas.github.io/2016/04/27/python-nested-list-comprehensions/\n",
    "\n",
    "# for a in b:\n",
    "#     for x in y:\n",
    "#         x\n",
    "    \n",
    "#     [x for x in y if x > 2 ] for a in b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a7e0cb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pitches = get_unique_pitches_one_oct(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f9a56e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pitches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dfb033",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chords = [key for key, value in chords_dict.items() if set(value).issubset(pitches)]\n",
    "\n",
    "# for key, value in chords_dict.items():\n",
    "#     if set(value).issubset(pitches):\n",
    "#         chords.append(key)\n",
    "        \n",
    "# https://stackoverflow.com/questions/3847386/how-to-test-if-a-list-contains-another-list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e285d19",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48c06c0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit([chords_dict.keys()])\n",
    "mlb.classes_\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/50030751/how-do-i-use-onehotencoder-on-a-pandas-series-of-lists\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc32b017",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mlb.transform([chords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1e41d2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Iterating for all X_train\n",
    "test = [[X_train[0], chords]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00024ed5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test2 = [[X_train]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e802325b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4a5215",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(test, columns=['Acc', 'Chords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67283763",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b8beb1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chords_encoded = mlb.transform(df['Chords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2546824",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['A#_majeur'] = 'test'\n",
    "df['A#_mineur'] = 'test'\n",
    "df['A_majeur'] = 'test'\n",
    "df['A_mineur'] = 'test'\n",
    "df['B_majeur'] = 'test'\n",
    "df['B_mineur'] = 'test'\n",
    "df['C#_majeur'] = 'test'\n",
    "df['C#_mineur'] = 'test'\n",
    "df['C_majeur'] = 'test'\n",
    "df['C_mineur'] = 'test'\n",
    "df['D#_majeur'] = 'test'\n",
    "df['D#_mineur'] = 'test'\n",
    "df['D_majeur'] = 'test'\n",
    "df['D_mineur'] = 'test'\n",
    "df['E_majeur'] = 'test'\n",
    "df['E_mineur'] = 'test'\n",
    "df['F#_majeur'] = 'test'\n",
    "df['F#_mineur'] = 'test'\n",
    "df['F_majeur'] = 'test'\n",
    "df['F_mineur'] = 'test'\n",
    "df['G#_majeur'] = 'test'\n",
    "df['G#_mineur'] = 'test'\n",
    "df['G_majeur'] = 'test'\n",
    "df['G_mineur'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1976f5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['A#_majeur', df['A#_mineur'], df['A_majeur'], df['A_mineur'], df['B_majeur'], df['B_mineur'], df['C#_majeur'], df['C#_mineur'], df['C_majeur'], df['C_mineur'],df['D#_majeur'], df['D#_mineur'], df['D_majeur'], df['D_mineur'], df['E_majeur'],df['E_mineur'], df['F#_majeur'], df['F#_mineur'], df['F_majeur'], df['F_mineur'],df['G#_majeur'], df['G#_mineur'], df['G_majeur'], df['G_mineur'] = chords_encoded.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7447b69f",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ae20c3",
   "metadata": {},
   "source": [
    "### One Sample for mean velocity of 1 sec\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051c85e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b105e4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_velocities_for_each_sec(acc, fs=50):\n",
    "    \n",
    "    velocities = []\n",
    "    \n",
    "\n",
    "    for start_index in range(0, len(acc),fs):\n",
    "        sample = acc[start_index:start_index+fs]\n",
    "        sample = np.minimum(sample, np.full(sample.shape, 127))\n",
    "        mean_velocity = int(sample[sample>0].mean()) if sample[sample>0].size > 0 else 0\n",
    "        \n",
    "        \n",
    "        \n",
    "        velocities.append(mean_velocity)\n",
    "    \n",
    "    return velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e97f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ternary Operation Python\n",
    "fruit = 'Apple'\n",
    "isApple = True if fruit == 'Apple' else False\n",
    "isApple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88f7285",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_velocities_for_each_sec(X_train[46])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9b87e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # OLD VERSION\n",
    "# def get_velocities_for_each_sec(acc, fs=50):\n",
    "#     composite_list = [acc[x:x+fs] for x in range(0, len(acc),fs)]\n",
    "    \n",
    "#     velocities_per_instants = []\n",
    "#     velocities_per_second = []\n",
    "#     mean_velocity_per_second = []\n",
    "    \n",
    "#     for instants in composite_list: # Pour chaque liste de 50 instants\n",
    "#         velocities_per_instants = []\n",
    "#         for instant in instants: # Pour chaque instant de 128 notes          \n",
    "#             velocity_per_instant = [vel for vel in instant if vel > 0] # Conserve la vélocité si > 0\n",
    "#             for index, vel in enumerate(velocity_per_instant):\n",
    "#                 if vel > 127:       \n",
    "#                     velocity_per_instant[index] = 127 # Remplace la vélocité par 127 si elle est trop élevée\n",
    "#             velocities_per_instants.append(velocity_per_instant) # On appende 50 fois les vélocités de l'instant\n",
    "#         velocities_per_instants = [vel for inst in velocities_per_instants for vel in inst]\n",
    "#         velocities_per_second.append(velocities_per_instants) # On appende 10 fois nos lists de 50 listes de vel\n",
    "        \n",
    "# #         mean_velocity_per_second = [int(np.mean(vels)) for vels in velocities_per_second]\n",
    "\n",
    "#         for vels in velocities_per_second:\n",
    "#             if vels != []:\n",
    "#                 elt = int(np.mean(vels))\n",
    "#             else:\n",
    "                \n",
    "#                 elt = 0\n",
    "#         mean_velocity_per_second.append(elt)\n",
    "                \n",
    "#     return mean_velocity_per_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74e1b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def velocities_for_dataset(dataset):\n",
    "    df_list = []\n",
    "    for data in dataset:\n",
    "        velocities = get_velocities_for_each_sec(data)\n",
    "        df_list.append(velocities)        \n",
    "    return pd.DataFrame(df_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247a7df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_velocities_for_each_sec(X_train[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1734cbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_velocities  = velocities_for_dataset(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccf5561",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_velocities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a67320",
   "metadata": {},
   "source": [
    "##### Test & Info sur map/filter in Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de795249",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_test = [1,2,3,4,5]\n",
    "for num in list_test:\n",
    "    num = 2\n",
    "list_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521b8d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, num in enumerate(list_test):\n",
    "    list_test[index] = 2\n",
    "list_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997d72f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_test = [2 for num in list_test]\n",
    "list_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abb2479",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_test = [1,2,3,4,5]\n",
    "\n",
    "list(map(lambda x:0 if x==2 else x, list_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94efea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_test = [1,2,3,4,5]\n",
    "list(filter(lambda x: x==2, list_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7807d2c",
   "metadata": {},
   "source": [
    "### Function to do it for all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f30fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for X in X_train:\n",
    "#     print('hello')\n",
    "test = [[X_train[0], chords], [X_train[0], chords]]\n",
    "df_test = pd.DataFrame(test, columns=['Acc', 'Chords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e156e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_pitches_one_oct(acc):  \n",
    "    pitches = [index % 12 for instant in acc.T for index, vel in enumerate(instant) if vel >0]    \n",
    "    return list(set(pitches))\n",
    "\n",
    "\n",
    "def adding_chords_info(chords_df_path, dataset):\n",
    "    chords_df = pd.read_csv(chords_df_path, sep=\";\")\n",
    "    chords_dict = chords_df.set_index('Chord').T.to_dict('list')\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    mlb.fit([chords_dict.keys()])\n",
    "    df_list = []\n",
    "    for data in dataset:\n",
    "        pitches = get_unique_pitches_one_oct(data)\n",
    "        \n",
    "        \n",
    "        # Utilisation de la fonction all\n",
    "#         chords = [key for key, value in chords_dict.items() if all(pitch in pitches for pitch in chord)]\n",
    "        \n",
    "        chords = [key for key, value in chords_dict.items() if set(value).issubset(pitches)]\n",
    "        list_for_df = [[data, chords]]\n",
    "        df_list.append([list_for_df, chords])  \n",
    "    df = pd.DataFrame(df_list, columns=['Acc', 'Chords'])\n",
    "    chords_encoded = mlb.transform(df['Chords'])\n",
    "    \n",
    "    df['A#_majeur'], df['A#_mineur'], df['A_majeur'], df['A_mineur'], df['B_majeur'], df['B_mineur'], df['C#_majeur'], df['C#_mineur'], df['C_majeur'], df['C_mineur'], df['D#_majeur'], df['D#_mineur'], df['D_majeur'], df['D_mineur'], df['E_majeur'], df['E_mineur'], df['F#_majeur'], df['F#_mineur'], df['F_majeur'], df['F_mineur'], df['G#_majeur'], df['G#_mineur'], df['G_majeur'], df['G_mineur'] = chords_encoded.T\n",
    "    return df.drop(columns='Chords')\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ab7ef13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = adding_chords_info('raw_data/chords_midi.csv', X_train[0:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af272d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc</th>\n",
       "      <th>A#_majeur</th>\n",
       "      <th>A#_mineur</th>\n",
       "      <th>A_majeur</th>\n",
       "      <th>A_mineur</th>\n",
       "      <th>B_majeur</th>\n",
       "      <th>B_mineur</th>\n",
       "      <th>C#_majeur</th>\n",
       "      <th>C#_mineur</th>\n",
       "      <th>C_majeur</th>\n",
       "      <th>...</th>\n",
       "      <th>E_majeur</th>\n",
       "      <th>E_mineur</th>\n",
       "      <th>F#_majeur</th>\n",
       "      <th>F#_mineur</th>\n",
       "      <th>F_majeur</th>\n",
       "      <th>F_mineur</th>\n",
       "      <th>G#_majeur</th>\n",
       "      <th>G#_mineur</th>\n",
       "      <th>G_majeur</th>\n",
       "      <th>G_mineur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Acc  A#_majeur  A#_mineur  \\\n",
       "0  [[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...          0          0   \n",
       "\n",
       "   A_majeur  A_mineur  B_majeur  B_mineur  C#_majeur  C#_mineur  C_majeur  \\\n",
       "0         0         1         0         0          0          0         1   \n",
       "\n",
       "   ...  E_majeur  E_mineur  F#_majeur  F#_mineur  F_majeur  F_mineur  \\\n",
       "0  ...         0         1          0          0         0         0   \n",
       "\n",
       "   G#_majeur  G#_mineur  G_majeur  G_mineur  \n",
       "0          0          0         1         0  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec26f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f86b9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['A#_majeur', 'A#_mineur', 'A_majeur', 'A_mineur', 'B_majeur',\n",
    "       'B_mineur', 'C#_majeur', 'C#_mineur', 'C_majeur', 'C_mineur',\n",
    "       'D#_majeur', 'D#_mineur', 'D_majeur', 'D_mineur', 'E_majeur',\n",
    "       'E_mineur', 'F#_majeur', 'F#_mineur', 'F_majeur', 'F_mineur',\n",
    "       'G#_majeur', 'G#_mineur', 'G_majeur', 'G_mineur']].head(1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7890ec",
   "metadata": {},
   "source": [
    "## Get Samples & Fix Features/Target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0244889b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Concat Samples into one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b03bcf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df0 = joblib.load(f'raw_data/dataframes_sample/dataframe_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3fb55c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=['accompaniment', 'melody_pitches', 'melody_velocities'])\n",
    "for i in range(10):\n",
    "    loaded = joblib.load(f'raw_data/dataframes_sample/dataframe_{i}')\n",
    "    data = pd.concat((data, loaded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eec31c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcae6ec",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "acc = [np.asarray(data['accompaniment'].iloc[0].todense()).T, np.asarray(data['accompaniment'].iloc[1].todense()).T]\n",
    "pitch = [np.asarray(data['melody_pitches'].iloc[0].todense()).reshape(-1), np.asarray(data['melody_pitches'].iloc[1].todense()).reshape(-1)]\n",
    "velo = [np.asarray(data['melody_velocities'].iloc[0].todense()).reshape(-1), np.asarray(data['melody_velocities'].iloc[0].todense()).reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d76d734",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "acc_as_array = np.array(acc)\n",
    "pitch_as_array = np.array(pitch)\n",
    "velo_as_array = np.array(velo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedf25cd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "acc_as_array.shape\n",
    "# n_seqs, n_observations, n_features\n",
    "# Pour garder le voc des cours ML n_obs, n_indiv, n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a76a581",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pitch_as_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f22308",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_dumb_train = acc_as_array\n",
    "y_pitch_dumb_train = pitch_as_array\n",
    "y_velocity_dumb_train = velo_as_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d986d8f8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for column in data:\n",
    "    for i in range(len(data[column])):\n",
    "        data[column][i] = np.asarray(data[column][i].todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895d82a0",
   "metadata": {},
   "source": [
    "### Split Features & Target + Train Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5e78b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old version\n",
    "\n",
    "# X, y_pitch, y_velocity = joblib.load(f'raw_data/nparray_samples/nparray0')\n",
    "# for i in range(1, 10):\n",
    "#     loaded = joblib.load(f'raw_data/nparray_samples/nparray{i}')\n",
    "#     np.concatenate((X, loaded[0]))\n",
    "#     np.concatenate((y_pitch, loaded[1]))\n",
    "    \n",
    "#     np.concatenate((y_velocity, loaded[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d38e1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7d55c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = joblib.load(f'raw_data/nparray_samples/piece0') # No .. because of os change dir earlier\n",
    "\n",
    "for i in range(1, 10):\n",
    "    loaded = joblib.load(f'raw_data/nparray_samples/piece{i}')\n",
    "    \n",
    "    X = np.concatenate((X, loaded[0]))\n",
    "    y = np.concatenate((y, loaded[1]))\n",
    "    \n",
    "# PROBLEME DE SHAPE TO BE FIXED\n",
    "\n",
    "# RESHAPE NEEDED FOR TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b93a7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23ebf2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95, 128, 500)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dc27f6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## DL Models Tests\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8401b5",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Test Model from Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0b983f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/CyberZHG/keras-self-attention/blob/master/keras_self_attention/seq_self_attention.py\n",
    "class SeqSelfAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    ATTENTION_TYPE_ADD = 'additive'\n",
    "    ATTENTION_TYPE_MUL = 'multiplicative'\n",
    "\n",
    "    def __init__(self,\n",
    "                 units=32,\n",
    "                 attention_width=None,\n",
    "                 attention_type=ATTENTION_TYPE_ADD,\n",
    "                 return_attention=False,\n",
    "                 history_only=False,\n",
    "                 kernel_initializer='glorot_normal',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 use_additive_bias=True,\n",
    "                 use_attention_bias=True,\n",
    "                 attention_activation=None,\n",
    "                 attention_regularizer_weight=0.0,\n",
    "                 **kwargs):\n",
    "        \"\"\"Layer initialization.\n",
    "        For additive attention, see: https://arxiv.org/pdf/1806.01264.pdf\n",
    "        :param units: The dimension of the vectors that used to calculate the attention weights.\n",
    "        :param attention_width: The width of local attention.\n",
    "        :param attention_type: 'additive' or 'multiplicative'.\n",
    "        :param return_attention: Whether to return the attention weights for visualization.\n",
    "        :param history_only: Only use historical pieces of data.\n",
    "        :param kernel_initializer: The initializer for weight matrices.\n",
    "        :param bias_initializer: The initializer for biases.\n",
    "        :param kernel_regularizer: The regularization for weight matrices.\n",
    "        :param bias_regularizer: The regularization for biases.\n",
    "        :param kernel_constraint: The constraint for weight matrices.\n",
    "        :param bias_constraint: The constraint for biases.\n",
    "        :param use_additive_bias: Whether to use bias while calculating the relevance of inputs features\n",
    "                                  in additive mode.\n",
    "        :param use_attention_bias: Whether to use bias while calculating the weights of attention.\n",
    "        :param attention_activation: The activation used for calculating the weights of attention.\n",
    "        :param attention_regularizer_weight: The weights of attention regularizer.\n",
    "        :param kwargs: Parameters for parent class.\n",
    "        \"\"\"\n",
    "        self.supports_masking = True\n",
    "        self.units = units\n",
    "        self.attention_width = attention_width\n",
    "        self.attention_type = attention_type\n",
    "        self.return_attention = return_attention\n",
    "        self.history_only = history_only\n",
    "        if history_only and attention_width is None:\n",
    "            self.attention_width = int(1e9)\n",
    "\n",
    "        self.use_additive_bias = use_additive_bias\n",
    "        self.use_attention_bias = use_attention_bias\n",
    "        self.kernel_initializer = tf.keras.initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = tf.keras.initializers.get(bias_initializer)\n",
    "        self.kernel_regularizer = tf.keras.regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = tf.keras.regularizers.get(bias_regularizer)\n",
    "        self.kernel_constraint = tf.keras.constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = tf.keras.constraints.get(bias_constraint)\n",
    "        self.attention_activation = tf.keras.activations.get(attention_activation)\n",
    "        self.attention_regularizer_weight = attention_regularizer_weight\n",
    "        self._backend = tf.keras.backend.backend()\n",
    "\n",
    "        if attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n",
    "            self.Wx, self.Wt, self.bh = None, None, None\n",
    "            self.Wa, self.ba = None, None\n",
    "        elif attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n",
    "            self.Wa, self.ba = None, None\n",
    "        else:\n",
    "            raise NotImplementedError('No implementation for attention type : ' + attention_type)\n",
    "\n",
    "        super(SeqSelfAttention, self).__init__(**kwargs)\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'units': self.units,\n",
    "            'attention_width': self.attention_width,\n",
    "            'attention_type': self.attention_type,\n",
    "            'return_attention': self.return_attention,\n",
    "            'history_only': self.history_only,\n",
    "            'use_additive_bias': self.use_additive_bias,\n",
    "            'use_attention_bias': self.use_attention_bias,\n",
    "            'kernel_initializer': tf.keras.regularizers.serialize(self.kernel_initializer),\n",
    "            'bias_initializer': tf.keras.regularizers.serialize(self.bias_initializer),\n",
    "            'kernel_regularizer': tf.keras.regularizers.serialize(self.kernel_regularizer),\n",
    "            'bias_regularizer': tf.keras.regularizers.serialize(self.bias_regularizer),\n",
    "            'kernel_constraint': tf.keras.constraints.serialize(self.kernel_constraint),\n",
    "            'bias_constraint': tf.keras.constraints.serialize(self.bias_constraint),\n",
    "            'attention_activation': tf.keras.activations.serialize(self.attention_activation),\n",
    "            'attention_regularizer_weight': self.attention_regularizer_weight,\n",
    "        }\n",
    "        base_config = super(SeqSelfAttention, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape = input_shape[0]\n",
    "        if self.attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n",
    "            self._build_additive_attention(input_shape)\n",
    "        elif self.attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n",
    "            self._build_multiplicative_attention(input_shape)\n",
    "        super(SeqSelfAttention, self).build(input_shape)\n",
    "        \n",
    "    def _build_additive_attention(self, input_shape):\n",
    "        feature_dim = input_shape[2]\n",
    "\n",
    "        self.Wt = self.add_weight(shape=(feature_dim, self.units),\n",
    "                                  name='{}_Add_Wt'.format(self.name),\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        self.Wx = self.add_weight(shape=(feature_dim, self.units),\n",
    "                                  name='{}_Add_Wx'.format(self.name),\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        if self.use_additive_bias:\n",
    "            self.bh = self.add_weight(shape=(self.units,),\n",
    "                                      name='{}_Add_bh'.format(self.name),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      regularizer=self.bias_regularizer,\n",
    "                                      constraint=self.bias_constraint)\n",
    "\n",
    "        self.Wa = self.add_weight(shape=(self.units, 1),\n",
    "                                  name='{}_Add_Wa'.format(self.name),\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        if self.use_attention_bias:\n",
    "            self.ba = self.add_weight(shape=(1,),\n",
    "                                      name='{}_Add_ba'.format(self.name),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      regularizer=self.bias_regularizer,\n",
    "                                      constraint=self.bias_constraint)\n",
    "    def _build_multiplicative_attention(self, input_shape):\n",
    "        feature_dim = input_shape[2]\n",
    "\n",
    "        self.Wa = self.add_weight(shape=(feature_dim, feature_dim),\n",
    "                                  name='{}_Mul_Wa'.format(self.name),\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        if self.use_attention_bias:\n",
    "            self.ba = self.add_weight(shape=(1,),\n",
    "                                      name='{}_Mul_ba'.format(self.name),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      regularizer=self.bias_regularizer,\n",
    "                                      constraint=self.bias_constraint)\n",
    "    def call(self, inputs, mask=None, **kwargs):\n",
    "        if isinstance(inputs, list):\n",
    "            inputs, positions = inputs\n",
    "            positions = K.cast(positions, 'int32')\n",
    "            mask = mask[1]\n",
    "        else:\n",
    "            positions = None\n",
    "\n",
    "        input_len = K.shape(inputs)[1]\n",
    "\n",
    "        if self.attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n",
    "            e = self._call_additive_emission(inputs)\n",
    "        elif self.attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n",
    "            e = self._call_multiplicative_emission(inputs)\n",
    "\n",
    "        if self.attention_activation is not None:\n",
    "            e = self.attention_activation(e)\n",
    "        e = K.exp(e - K.max(e, axis=-1, keepdims=True))\n",
    "        if self.attention_width is not None:\n",
    "            ones = tf.ones((input_len, input_len))\n",
    "            if self.history_only:\n",
    "                local = tf.linalg.band_part(\n",
    "                    ones,\n",
    "                    K.minimum(input_len, self.attention_width - 1),\n",
    "                    0,\n",
    "                )\n",
    "            else:\n",
    "                local = tf.linalg.band_part(\n",
    "                    ones,\n",
    "                    K.minimum(input_len, self.attention_width // 2),\n",
    "                    K.minimum(input_len, (self.attention_width - 1) // 2),\n",
    "                )\n",
    "            e = e * K.expand_dims(local, 0)\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            mask = K.expand_dims(mask)\n",
    "            e = K.permute_dimensions(K.permute_dimensions(e * mask, (0, 2, 1)) * mask, (0, 2, 1))\n",
    "                # a_{t} = \\text{softmax}(e_t)\n",
    "        s = K.sum(e, axis=-1)\n",
    "        s = K.tile(K.expand_dims(s, axis=-1), K.stack([1, 1, input_len]))\n",
    "        a = e / (s + K.epsilon())\n",
    "\n",
    "        # l_t = \\sum_{t'} a_{t, t'} x_{t'}\n",
    "        v = K.batch_dot(a, inputs)\n",
    "        if self.attention_regularizer_weight > 0.0:\n",
    "            self.add_loss(self._attention_regularizer(a))\n",
    "\n",
    "        if positions is not None:\n",
    "            pos_num = K.shape(positions)[1]\n",
    "            batch_indices = K.tile(K.expand_dims(K.arange(K.shape(inputs)[0]), axis=-1), K.stack([1, pos_num]))\n",
    "            pos_indices = K.stack([batch_indices, positions], axis=-1)\n",
    "            v = tf.gather_nd(v, pos_indices)\n",
    "            a = tf.gather_nd(a, pos_indices)\n",
    "\n",
    "        if self.return_attention:\n",
    "            return [v, a]\n",
    "        return v\n",
    "    def _call_additive_emission(self, inputs):\n",
    "        input_shape = K.shape(inputs)\n",
    "        batch_size, input_len = input_shape[0], input_shape[1]\n",
    "\n",
    "        # h_{t, t'} = \\tanh(x_t^T W_t + x_{t'}^T W_x + b_h)\n",
    "        q, k = K.dot(inputs, self.Wt), K.dot(inputs, self.Wx)\n",
    "        q = K.tile(K.expand_dims(q, 2), K.stack([1, 1, input_len, 1]))\n",
    "        k = K.tile(K.expand_dims(k, 1), K.stack([1, input_len, 1, 1]))\n",
    "        if self.use_additive_bias:\n",
    "            h = K.tanh(q + k + self.bh)\n",
    "        else:\n",
    "            h = K.tanh(q + k)\n",
    "\n",
    "        # e_{t, t'} = W_a h_{t, t'} + b_a\n",
    "        if self.use_attention_bias:\n",
    "            e = K.reshape(K.dot(h, self.Wa) + self.ba, (batch_size, input_len, input_len))\n",
    "        else:\n",
    "            e = K.reshape(K.dot(h, self.Wa), (batch_size, input_len, input_len))\n",
    "        return e\n",
    "\n",
    "    def _call_multiplicative_emission(self, inputs):\n",
    "        # e_{t, t'} = x_t^T W_a x_{t'} + b_a\n",
    "        e = K.batch_dot(K.dot(inputs, self.Wa), K.permute_dimensions(inputs, (0, 2, 1)))\n",
    "        if self.use_attention_bias:\n",
    "            e = e + self.ba\n",
    "        return e\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape, pos_shape = input_shape\n",
    "            output_shape = (input_shape[0], pos_shape[1], input_shape[2])\n",
    "        else:\n",
    "            output_shape = input_shape\n",
    "        if self.return_attention:\n",
    "            attention_shape = (input_shape[0], output_shape[1], input_shape[1])\n",
    "            return [output_shape, attention_shape]\n",
    "        return output_shape\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        if isinstance(inputs, list):\n",
    "            mask = mask[1]\n",
    "        if self.return_attention:\n",
    "            return [mask, None]\n",
    "        return mask\n",
    "\n",
    "    def _attention_regularizer(self, attention):\n",
    "        batch_size = K.cast(K.shape(attention)[0], K.floatx())\n",
    "        input_len = K.shape(attention)[-1]\n",
    "        return self.attention_regularizer_weight * K.sum(K.square(K.batch_dot(\n",
    "            attention,\n",
    "            K.permute_dimensions(attention, (0, 2, 1))) - tf.eye(input_len))) / batch_size\n",
    "\n",
    "    @staticmethod\n",
    "    def get_custom_objects():\n",
    "      return {'SeqSelfAttention': SeqSelfAttention}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effbdc69",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_model(seq_len, unique_notes, dropout=0.3, output_emb=100, rnn_unit=128, dense_unit=64):\n",
    "  inputs = tf.keras.layers.Input(shape=(seq_len,))\n",
    "  embedding = tf.keras.layers.Embedding(input_dim=unique_notes+1, output_dim=output_emb, input_length=seq_len)(inputs)\n",
    "  forward_pass = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(rnn_unit, return_sequences=True))(embedding)\n",
    "  forward_pass , att_vector = SeqSelfAttention(\n",
    "      return_attention=True,\n",
    "      attention_activation='sigmoid', \n",
    "      attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL,\n",
    "      attention_width=50, \n",
    "      kernel_regularizer=tf.keras.regularizers.l2(1e-4),\n",
    "      bias_regularizer=tf.keras.regularizers.l1(1e-4),\n",
    "      attention_regularizer_weight=1e-4,\n",
    "  )(forward_pass)\n",
    "  forward_pass = tf.keras.layers.Dropout(dropout)(forward_pass)\n",
    "  forward_pass = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(rnn_unit, return_sequences=True))(forward_pass)\n",
    "  forward_pass , att_vector2 = SeqSelfAttention(\n",
    "      return_attention=True,\n",
    "      attention_activation='sigmoid', \n",
    "      attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL,\n",
    "      attention_width=50, \n",
    "      kernel_regularizer=tf.keras.regularizers.l2(1e-4),\n",
    "      bias_regularizer=tf.keras.regularizers.l1(1e-4),\n",
    "      attention_regularizer_weight=1e-4,\n",
    "  )(forward_pass)\n",
    "  forward_pass = tf.keras.layers.Dropout(dropout)(forward_pass)\n",
    "  forward_pass = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(rnn_unit))(forward_pass)\n",
    "  forward_pass = tf.keras.layers.Dropout(dropout)(forward_pass)\n",
    "  forward_pass = tf.keras.layers.Dense(dense_unit)(forward_pass)\n",
    "  forward_pass = tf.keras.layers.LeakyReLU()(forward_pass)\n",
    "  outputs = tf.keras.layers.Dense(unique_notes+1, activation = \"softmax\")(forward_pass)\n",
    "\n",
    "  model = tf.keras.Model(inputs=inputs, outputs=outputs, name='generate_scores_rnn')\n",
    "  return model\n",
    "\n",
    "model = create_model(seq_len, unique_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bc8697",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Simple Model with LSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c5e1e7",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### LSTM - Classique\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0899836a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### LSTM - Classique - Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eb6647",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###### Model Creation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff25f6b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(500, 128), name='main_input') # TO BE MODIFIED - SPARSE MATRIX  #input shape 128 * 10_000\n",
    "# shape = X_train[0].shape\n",
    "# Envoi d'un sparse tensor sinon sparse matrix\n",
    "# Envoyer en input sparse ou brut est-ce que ça change les perfs ou non\n",
    "# https://stackoverflow.com/questions/20459536/convert-pandas-dataframe-to-sparse-numpy-matrix-directly\n",
    "\n",
    "\n",
    "\n",
    "main_branch = layers.LSTM(units=128, activation='tanh', return_sequences=True)(inputs)\n",
    "main_branch = layers.LSTM(units=128, activation='tanh')(main_branch)\n",
    "main_branch = layers.Dense(64, activation='relu')(main_branch)\n",
    "# DO WE NEED TWO LAYERS FOR REGRESSION AS WELL ?\n",
    "pitch_branch = layers.Dense(500, activation='relu', name='pitch_output')(main_branch)\n",
    "velocity_branch = layers.Dense(500, activation='relu', name='velocity_output')(main_branch)\n",
    "\n",
    "\n",
    "model_lstm_reg = models.Model(inputs = inputs, outputs = [pitch_branch, velocity_branch])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30939326",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###### Model Summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de36752",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_lstm_reg.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebdb7d2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###### Model Compilation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e7fce2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_lstm_reg.compile(loss='mse', optimizer='rmsprop') # LOSS TO REVIEW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03c06fc",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_lstm_reg.fit(X_train,\n",
    "              {'pitch_output': y_train_pitch, 'velocity_output': y_train_pitch},   \n",
    "              epochs=3,    \n",
    "              verbose=1,    \n",
    "                   \n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4531a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e1ab6d",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = model_lstm_reg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338fb244",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bba6761",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predictions[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c5311c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512bcfa6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/zero-inflated-regression-c7dfc656d8af\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba68dab",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### LSTM - Classique - Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c56d19b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###### Model Creation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80db6e26",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51d78f1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(500, 128), name='main_input') # TO BE MODIFIED - SPARSE MATRIX\n",
    "\n",
    "main_branch = layers.LSTM(units=128, activation='tanh', return_sequences=True)(inputs)\n",
    "main_branch = layers.LSTM(units=128, activation='tanh')(main_branch)\n",
    "main_branch = layers.Dense(64, activation='relu')(main_branch)\n",
    "               \n",
    "# 2 SORTIES POUR CHAQUE PREDICTION\n",
    "# Multitask learning\n",
    "# https://github.com/rahul-pande/faces-mtl\n",
    "# https://github.com/rahul-pande/faces-mtl/blob/master/faces_mtl_age_gender.ipynb\n",
    "\n",
    "pitch_branch = layers.Dense(500, activation='softmax', name='pitch_output')(main_branch)\n",
    "velocity_branch = layers.Dense(500, activation='softmax', name='velocity_output')(main_branch)\n",
    "\n",
    "\n",
    "\n",
    "# Cannot use Sequential because several outputs\n",
    "model_lstm_class = models.Model(inputs = inputs, outputs = [pitch_branch, velocity_branch])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a759806c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###### Model Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105faf39",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_lstm_class.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2296b39a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###### Model Compilation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daa9d51",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_lstm_class.compile(loss='mse', optimizer='rmsprop') # LOSS TO REVIEW\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5956ec15",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_lstm_class.fit(X_train,\n",
    "                     {'pitch_output': y_train_pitch, 'velocity_output': y_train_pitch},\n",
    "                     epochs=3,\n",
    "                     verbose=1,\n",
    "                     validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7db2cb6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_lstm_class.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46707a97",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### LSTM - Bidirectional\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b6a61b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### LSTM - Bidirectional - Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a4182f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###### Model Creation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ba41d3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# https://keras.io/examples/nlp/bidirectional_lstm_imdb/\n",
    "# https://machinelearningmastery.com/develop-bidirectional-lstm-sequence-classification-python-keras/\n",
    "# Try all methods concat, sum etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fd9fab",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbc2e8a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(500, 128), name='main_input') # TO BE MODIFIED - SPARSE MATRIX\n",
    "\n",
    "# Add 2 bidirectional LSTMs\n",
    "main_branch = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(inputs)\n",
    "\n",
    "main_branch = layers.Bidirectional(layers.LSTM(128, return_sequences=False))(main_branch)\n",
    "\n",
    "\n",
    "pitch_branch = layers.Dense(500, activation='relu', name='pitch_output')(main_branch)\n",
    "velocity_branch = layers.Dense(500, activation='relu', name='velocity_output')(main_branch)\n",
    "\n",
    "model_lstm_bin_reg = models.Model(inputs = inputs, outputs = [pitch_branch, velocity_branch])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddd8cef",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Model Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c22efd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_lstm_bin_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e3d92e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###### Model Compilation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984f9474",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_lstm_bin_reg.compile(loss='mse', optimizer='rmsprop') # LOSS TO REVIEW\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de89d08",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_lstm_bin_reg.fit(X_train,\n",
    "                       \n",
    "                       {'pitch_output': y_train_pitch, 'velocity_output': y_train_pitch},\n",
    "                       epochs=3,\n",
    "                       \n",
    "                       verbose=1,\n",
    "                       validation_split=0.3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c87589",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_lstm_bin_reg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfaac34",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### LSTM - Bidirectional - Classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357d79a1",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Model Creation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18808861",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(10000, 128), name='main_input') # TO BE MODIFIED - SPARSE MATRIX\n",
    "# Add 2 bidirectional LSTMs\n",
    "main_branch = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(main_branch)\n",
    "main_branch = layers.Bidirectional(layers.LSTM(128))(main_branch)\n",
    "# Add a classifier\n",
    "pitch_branch = layers.Dense(128, activation='softmax', name='pitch_output')(main_branch)\n",
    "velocity_branch = layers.Dense(128, activation='softmax', name='velocity_output')(main_branch)\n",
    "model_lstm_bin_class = models.Model(inputs = inputs, outputs = [pitch_branch, velocity_branch])\n",
    "model_lstm_bin_class.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca666cf9",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Model Compilation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5278ab1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_lstm_bin_class.compile(loss='mse', optimizer='rmsprop') # LOSS TO REVIEW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c09d61a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf460b5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/CyberZHG/keras-self-attention -> Try the basic use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8300fb0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from keras_self_attention import SeqSelfAttention\n",
    "\n",
    "model_self_test = models.Sequential()\n",
    "model_self_test.add(layers.Bidirectional(layers.LSTM(units=128, return_sequences=True)))\n",
    "model_self_test.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "model_self_test.add(layers.Dense(units=64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4a29f4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(500, 128), name='main_input') # TO BE MODIFIED - SPARSE MATRIX  #input shape 128 * 10_000\n",
    "# shape = X_train[0].shape\n",
    "# Envoi d'un sparse tensor sinon sparse matrix\n",
    "# Envoyer en input sparse ou brut est-ce que ça change les perfs ou non\n",
    "# https://stackoverflow.com/questions/20459536/convert-pandas-dataframe-to-sparse-numpy-matrix-directly\n",
    "\n",
    "main_branch = layers.LSTM(units=128, activation='tanh', return_sequences=True)(inputs)\n",
    "main_branch = layers.LSTM(units=128, activation='tanh', return_sequences=True)(main_branch)\n",
    "\n",
    "main_branch = SeqSelfAttention(attention_activation='sigmoid')(main_branch)\n",
    "\n",
    "main_branch = layers.Dense(64, activation='relu')(main_branch)\n",
    "\n",
    "pitch_branch = layers.Dense(500, activation='relu', name='pitch_output')(main_branch)\n",
    "velocity_branch = layers.Dense(500, activation='relu', name='velocity_output')(main_branch)\n",
    "\n",
    "model_self_test = models.Model(inputs = inputs, outputs = [pitch_branch, velocity_branch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80eac8b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_self_test.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850bf23b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_self_test.compile(loss='mse', optimizer='rmsprop') # LOSS TO REVIEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a794b1a1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_self_test.fit(X_train,\n",
    "                    \n",
    "                     {'pitch_output': y_train_pitch, 'velocity_output': y_train_pitch},\n",
    "                     epochs=3,\n",
    "                     verbose=1,\n",
    "                     validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479da2d6",
   "metadata": {},
   "source": [
    "## ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff12d9f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test with Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dac4a07",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0778ba",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(53, 500*128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f1e1f4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2f7c04",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37fc9b6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(24, 500*128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6456eec",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_train = np.vstack((y_train_pitch, y_train_velocity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bf9ecd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_test = np.vstack((y_test_pitch, y_test_velocity)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30fdda7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_train_pitch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d95370",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f1a771",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tree_class = DecisionTreeClassifier()\n",
    "\n",
    "# multi_tree_class = MultiOutputClassifier(tree_class, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00764a2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tree_class.fit(X_train, y_train_pitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4410ba9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predictions = tree_class.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5be3daf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predictions[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f264c28d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predictions[0][499]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257a2c8f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_test_pitch[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b2ae10",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predictions[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d864c2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_test_pitch[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b370980",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predictions[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acddb16d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "Xtest, y1test = make_classification(n_samples=10, n_features=100, n_informative=30, n_classes=3, random_state=1)\n",
    "\n",
    "y2test = shuffle(y1test, random_state=1)\n",
    "y3test = shuffle(y1test, random_state=2)\n",
    "Ytest = np.vstack((y1test, y2test, y3test)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84767a1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y1test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58330a17",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3774c6ac",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b7e508",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Ytest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1400f5c",
   "metadata": {},
   "source": [
    "### New Model in Parallel for Chords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d882b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pitches = adding_chords_info('raw_data/chords_midi.csv', X_train).drop(columns=\"Acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fb995c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_velocities  = velocities_for_dataset(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30006a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.merge(df_pitches, df_velocities, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37d9734",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3da01be",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.hstack((y_train_pitch, y_train_velocity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb61a54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a009476",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7f45c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d7ef57",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbaeaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6d4888",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471afef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2fb5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pitch = adding_chords_info('raw_data/chords_midi.csv', X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9465f167",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pitch = df_test_pitch[['A#_majeur', 'A#_mineur', 'A_majeur', 'A_mineur', 'B_majeur',      \n",
    "       'B_mineur', 'C#_majeur', 'C#_mineur', 'C_majeur', 'C_mineur',\n",
    "       'D#_majeur', 'D#_mineur', 'D_majeur', 'D_mineur', 'E_majeur',        \n",
    "       'E_mineur', 'F#_majeur', 'F#_mineur', 'F_majeur', 'F_mineur',\n",
    "       'G#_majeur', 'G#_mineur', 'G_majeur', 'G_mineur']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d477d29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_velocities = velocities_for_dataset(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130f437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.merge(df_test_pitch, df_test_velocities, left_index=True, right_index=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ac0f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4958c45d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be49d26f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test_pitch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c62e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_velocity[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f184eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity = np.full((500,), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac08bf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get back data - melody to piano roll & piano roll to pretty midi & write .mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c06954",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MIDIComposingAI import get_back_data\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22dbca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def melody_to_piano_roll(pitches, velocities):\n",
    "    \"\"\"\n",
    "    Create a piano roll from a list of pitches and a list of velocities\n",
    "    \"\"\"\n",
    "    piano_roll = np.zeros((128, 500))\n",
    "    \n",
    "\n",
    "    for i, (pitch, velocity) in enumerate(zip(pitches, velocities)):\n",
    "        \n",
    "        \n",
    "        if pitch > 0:\n",
    "            piano_roll[int(pitch)][i] = velocity\n",
    "\n",
    "    return piano_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58f3ac8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "piano_roll = melody_to_piano_roll(predictions[0][:499], predictions[0][499:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82b4e13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pm_predict = piano_roll_to_pretty_midi(piano_roll, fs=50, program=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0583a1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_predict.write('raw_data/prediction_test.mid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
