{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3164e872-e4e3-47ad-ac4e-b355f08f7e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "735c20ad-540a-4397-8371-cc1ecb796f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from MIDIComposingAI.create_dataset import *\n",
    "from MIDIComposingAI.get_back_data import *\n",
    "from MIDIComposingAI.utils import piano_roll_to_pretty_midi\n",
    "import joblib\n",
    "import pretty_midi\n",
    "from scipy.stats import entropy\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statistics import mean\n",
    "from os import listdir\n",
    "from os.path import getsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f317e269-2e4a-4680-a96c-73af183169cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = joblib.load('../raw_data/pretty_midi/(Day Dream) Prayer')\n",
    "file2 = pretty_midi.PrettyMIDI('../raw_data/1.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb9494e0-fa1d-4319-9728-cae86a60f04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern_recognition(acc, mel):\n",
    "\n",
    "    # Create list of pitches for each frame in accompaniment's piano roll\n",
    "    acc_pitches = []\n",
    "    \n",
    "    for frame in acc.T:\n",
    "        pitches = []\n",
    "        for vel in frame:\n",
    "            if vel > 0:\n",
    "                pitches.append(list(frame).index(vel))\n",
    "        if not pitches:\n",
    "            pitches.append(0)\n",
    "        acc_pitches.append(pitches)\n",
    "    \n",
    "    # Take the mean pitch of each frame\n",
    "    mean_pitches_acc = [(np.sum(pitches) / len(pitches)) for pitches in acc_pitches]\n",
    "    \n",
    "    # Get only the pitches (not the velocities)\n",
    "    melody_pitches = mel[:500]\n",
    "    \n",
    "    \n",
    "    # Create the pattern for accompaniment\n",
    "    acc_passed_pitch = []\n",
    "    pattern_acc = [0]\n",
    "    \n",
    "    for pitch in mean_pitches_acc:\n",
    "        if acc_passed_pitch:\n",
    "            if pitch != acc_passed_pitch[-1]:\n",
    "                relative_pitch = pitch - acc_passed_pitch[-1]\n",
    "                pattern_acc.append(relative_pitch)\n",
    "            else:\n",
    "                pattern_acc.append(pattern_acc[-1])\n",
    "        acc_passed_pitch.append(pitch)\n",
    "    \n",
    "    # Create the pattern for melody\n",
    "    mel_passed_pitch = []\n",
    "    pattern_mel = [0]\n",
    "    \n",
    "    for pitch in melody_pitches:\n",
    "        if mel_passed_pitch:\n",
    "            if pitch != mel_passed_pitch[-1]:\n",
    "                relative_pitch = pitch - mel_passed_pitch[-1]\n",
    "                pattern_mel.append(relative_pitch)\n",
    "            else:\n",
    "                pattern_mel.append(pattern_mel[-1])\n",
    "        mel_passed_pitch.append(pitch)\n",
    "        \n",
    "    return pattern_acc, pattern_mel\n",
    "\n",
    "def custom_metric(acc, pred):\n",
    "    \n",
    "    # Get the pitch pattern for both accompaniment and melody\n",
    "    pattern_acc, pattern_mel = pattern_recognition(acc, pred)\n",
    "    \n",
    "    # Compute the mean of velocities for both accompaniment and melody\n",
    "    list_mean_vel_acc = [\n",
    "        np.mean(\n",
    "            [vel for vel in frame if vel > 0]\n",
    "        )\n",
    "        for frame in acc.T\n",
    "        if np.sum(frame) > 0]\n",
    "    \n",
    "    # Check if the list is empty\n",
    "    if not list_mean_vel_acc:\n",
    "        list_mean_vel_acc = [0]\n",
    "    \n",
    "    mean_vel_acc = np.mean(list_mean_vel_acc)\n",
    "    \n",
    "    list_mean_vel_pred = [pred for pred in pred[500:] if pred > 0]\n",
    "    \n",
    "    # Check if the list is empty\n",
    "    if not list_mean_vel_pred:\n",
    "        list_mean_vel_pred = [0]\n",
    "        \n",
    "    mean_vel_pred = np.mean(list_mean_vel_pred)\n",
    "    \n",
    "    # Compute the diff beetween the two velocities mean\n",
    "    velocity_diff = abs(mean_vel_acc - mean_vel_pred)\n",
    "    \n",
    "    # Compute the \"diff pattern\" beetween accompaniment and melody\n",
    "    diff_pattern = np.array([abs(acc - mel) for acc, mel in zip(pattern_acc, pattern_mel)]).reshape(-1, 1)\n",
    "    \n",
    "    # Compute the entropy of the diff pattern\n",
    "    if np.sum(diff_pattern) == 0:\n",
    "        entropy_score = 0\n",
    "    else:\n",
    "        entropy_score = entropy(diff_pattern)[0]\n",
    "    \n",
    "    # Compute the final score\n",
    "    # score = (velocity_diff, entropy_score)\n",
    "    \n",
    "    return np.mean([entropy_score, velocity_diff])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fa89d6-6baf-4724-bb6b-3b072470e2b7",
   "metadata": {},
   "source": [
    "### Compute the score within a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd36444f-e22e-4242-9f8b-7197b561593f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeRegressor()\n",
    "\n",
    "grid = {\n",
    "    # 'criterion':               [\"squared_error\",\"friedman_mse\",\"absolute_error\",\"poisson\"],\n",
    "    'max_depth':               [None, 2, 12, 128],\n",
    "    'min_samples_split':       [2, 3, 5, 10],\n",
    "    'min_samples_leaf':        [1, 2, 3, 4],\n",
    "    'min_weight_fraction_leaf':[0.0, 0.2, 0.4, 0.5],\n",
    "    'max_leaf_nodes':          [None, 128, 12, 2],\n",
    "    # 'min_impurity_decrease':   [0.0, 0.2, 0.5, 0.8],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f45a401f-8356-4ebd-bf79-8ce7db5b0dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{\n",
    "    # 'criterion':crit,\n",
    "           'max_depth':max_d,\n",
    "           'min_samples_split':min_ss,\n",
    "           'min_samples_leaf':min_sl,\n",
    "           'min_weight_fraction_leaf':min_w,\n",
    "           'max_leaf_nodes':max_l}\n",
    "           # 'min_impurity_decrease':min_i}\n",
    "          # for crit in grid['criterion']\n",
    "          for max_d in grid['max_depth']\n",
    "          for min_ss in grid['min_samples_split']\n",
    "          for min_sl in grid['min_samples_leaf']\n",
    "          for min_w in grid['min_weight_fraction_leaf']\n",
    "          for max_l in grid['max_leaf_nodes']]\n",
    "          # for min_i in grid['min_impurity_decrease']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c13b36da-bc8c-49a6-bf8b-fdcd0eca9766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f789d7fb-6a5a-41e9-9d12-1ca467b3e8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 observations\n"
     ]
    }
   ],
   "source": [
    "path = '../raw_data/pretty_midi'\n",
    "directory = [file_name for file_name in listdir(path) if getsize(f'{path}/{file_name}') < 300_000]\n",
    "\n",
    "for i, file_name in enumerate(directory):\n",
    "    file = joblib.load(f'{path}/{file_name}')\n",
    "    if i == 0:\n",
    "        X, y = create_simple_dataset(file, ratio=0.2)\n",
    "    else:\n",
    "        try:\n",
    "            loaded = create_simple_dataset(file, ratio=0.2)\n",
    "            X = np.concatenate((X, loaded[0]))\n",
    "            y = np.concatenate((y, loaded[1]))\n",
    "            del([loaded, file])\n",
    "        except:\n",
    "            pass\n",
    "    if i % 10 == 0:\n",
    "        print(f'{X.shape[0]} observations')\n",
    "    if X.shape[0] >= 0:\n",
    "        break\n",
    "\n",
    "chord = adding_chords_info('../raw_data/chords_midi.csv', X)\n",
    "\n",
    "X_reshaped = X.reshape((X.shape[0], -1))\n",
    "X_reshaped = np.concatenate((chord, X_reshaped), axis=1, dtype=np.int8)\n",
    "\n",
    "y = y.reshape((y.shape[0], -1))\n",
    "\n",
    "X_train, X_test, X_reshaped_train, X_reshaped_test, y_train, y_test = train_test_split(X, X_reshaped, y, test_size=0.1, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e21e2aa-4624-4867-a53d-c2fa64fa1630",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 done\n",
      "11 done\n",
      "21 done\n",
      "31 done\n",
      "41 done\n",
      "51 done\n",
      "61 done\n",
      "71 done\n",
      "81 done\n",
      "91 done\n",
      "101 done\n",
      "111 done\n",
      "121 done\n",
      "131 done\n",
      "141 done\n",
      "151 done\n",
      "161 done\n",
      "171 done\n",
      "181 done\n",
      "191 done\n",
      "201 done\n",
      "211 done\n",
      "221 done\n",
      "231 done\n",
      "241 done\n",
      "251 done\n",
      "261 done\n",
      "271 done\n",
      "281 done\n",
      "291 done\n",
      "301 done\n",
      "311 done\n",
      "321 done\n",
      "331 done\n",
      "341 done\n",
      "351 done\n",
      "361 done\n",
      "371 done\n",
      "381 done\n",
      "391 done\n",
      "401 done\n",
      "411 done\n",
      "421 done\n",
      "431 done\n",
      "441 done\n",
      "451 done\n",
      "461 done\n",
      "471 done\n",
      "481 done\n",
      "491 done\n",
      "501 done\n",
      "511 done\n",
      "521 done\n",
      "531 done\n",
      "541 done\n",
      "551 done\n",
      "561 done\n",
      "571 done\n",
      "581 done\n",
      "591 done\n",
      "601 done\n",
      "611 done\n",
      "621 done\n",
      "631 done\n",
      "641 done\n",
      "651 done\n",
      "661 done\n",
      "671 done\n",
      "681 done\n",
      "691 done\n",
      "701 done\n",
      "711 done\n",
      "721 done\n",
      "731 done\n",
      "741 done\n",
      "751 done\n",
      "761 done\n",
      "771 done\n",
      "781 done\n",
      "791 done\n",
      "801 done\n",
      "811 done\n",
      "821 done\n",
      "831 done\n",
      "841 done\n",
      "851 done\n",
      "861 done\n",
      "871 done\n",
      "881 done\n",
      "891 done\n",
      "901 done\n",
      "911 done\n",
      "921 done\n",
      "931 done\n",
      "941 done\n",
      "951 done\n",
      "961 done\n",
      "971 done\n",
      "981 done\n",
      "991 done\n",
      "1001 done\n",
      "1011 done\n",
      "1021 done\n"
     ]
    }
   ],
   "source": [
    "params_and_scores = []\n",
    "\n",
    "for i, param in enumerate(params):\n",
    "    \n",
    "    tree = DecisionTreeRegressor(**param)\n",
    "    tree.fit(X_reshaped_train, y_train)\n",
    "    predictions = tree.predict(X_reshaped_test)\n",
    "    scores = [custom_metric(test, pred) for test, pred in zip(X_test, predictions)]\n",
    "    score = np.mean(scores)\n",
    "    params_and_scores.append({'params':param, 'score':score})\n",
    "    if i % 10 == 0:\n",
    "        print(f'{i+1} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "609e1c63-8cda-4648-a37e-8b2ca2b263f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (890067043.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_2069/890067043.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ps = [i, params['score'] for i, params in enumerate(params_and_scores)]\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "ps = [i, params['score'] for i, params in enumerate(params_and_scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08a99647-398d-4fba-a551-4f7de035161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = []\n",
    "for params in params_and_scores:\n",
    "    ps.append(params['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52c898ef-2655-4925-a7b7-0341487f6ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = params_and_scores[ps.index(np.min(ps))]\n",
    "worst_params = params_and_scores[ps.index(np.max(ps))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d94d1611-565b-4e32-8a38-7c63bab5ff53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': {'max_depth': None,\n",
       "  'min_samples_split': 3,\n",
       "  'min_samples_leaf': 1,\n",
       "  'min_weight_fraction_leaf': 0.0,\n",
       "  'max_leaf_nodes': 128},\n",
       " 'score': 4.371726592684219}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa8563ad-e58d-4613-ab5d-82b9d5f1ce4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': {'max_depth': None,\n",
       "  'min_samples_split': 3,\n",
       "  'min_samples_leaf': 4,\n",
       "  'min_weight_fraction_leaf': 0.2,\n",
       "  'max_leaf_nodes': None},\n",
       " 'score': 11.102578913240704}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worst_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f5a8b55-aeb9-44f6-899e-be32b763c809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': {'max_depth': None,\n",
       "  'min_samples_split': 3,\n",
       "  'min_samples_leaf': 1,\n",
       "  'min_weight_fraction_leaf': 0.0,\n",
       "  'max_leaf_nodes': 128},\n",
       " 'score': 4.371726592684219}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best params\n",
    "{'params': {'max_depth': None,\n",
    "  'min_samples_split': 3,\n",
    "  'min_samples_leaf': 1,\n",
    "  'min_weight_fraction_leaf': 0.0,\n",
    "  'max_leaf_nodes': 128},\n",
    " 'score': 4.371726592684219}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e13935-84fd-4a85-8277-bd5777401830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# worst params\n",
    "{'params': {'max_depth': None,\n",
    "  'min_samples_split': 3,\n",
    "  'min_samples_leaf': 4,\n",
    "  'min_weight_fraction_leaf': 0.2,\n",
    "  'max_leaf_nodes': None},\n",
    " 'score': 11.102578913240704}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
