{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3164e872-e4e3-47ad-ac4e-b355f08f7e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "735c20ad-540a-4397-8371-cc1ecb796f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from MIDIComposingAI.create_dataset import *\n",
    "from MIDIComposingAI.get_back_data import *\n",
    "from MIDIComposingAI.utils import piano_roll_to_pretty_midi\n",
    "import joblib\n",
    "import pretty_midi\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statistics import mean\n",
    "from os import listdir\n",
    "from os.path import getsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f317e269-2e4a-4680-a96c-73af183169cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = joblib.load('../raw_data/pretty_midi/(Day Dream) Prayer')\n",
    "file2 = pretty_midi.PrettyMIDI('../raw_data/1.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb9494e0-fa1d-4319-9728-cae86a60f04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern_recognition(acc, mel):\n",
    "    \"\"\"\n",
    "    Create a pattern of the evolution of relative pitch and rythm from accompaniment and melody\n",
    "    \"\"\"\n",
    "    # Create list of pitches for each frame in accompaniment's piano roll\n",
    "    acc_pitches = []\n",
    "    \n",
    "    for frame in acc.T:\n",
    "        pitches = []\n",
    "        for vel in frame:\n",
    "            if vel > 0:\n",
    "                pitches.append(list(frame).index(vel))\n",
    "        if not pitches:\n",
    "            pitches.append(0)\n",
    "        acc_pitches.append(pitches)\n",
    "    \n",
    "    # Take the mean pitch of each frame\n",
    "    mean_pitches_acc = [(np.sum(pitches) / len(pitches)) for pitches in acc_pitches]\n",
    "    \n",
    "    # Get only the pitches (not the velocities)\n",
    "    melody_pitches = mel[:500]\n",
    "    \n",
    "    \n",
    "    # Create the pattern for accompaniment\n",
    "    acc_passed_pitch = []\n",
    "    pitch_pattern_acc = [0]\n",
    "    \n",
    "    # Do we start with a note played or not ?\n",
    "    if mean_pitches_acc[0] > 0:\n",
    "        rythm_pattern_acc = [1]\n",
    "    else:\n",
    "        rythm_pattern_acc = [0]\n",
    "        \n",
    "    for pitch in mean_pitches_acc:\n",
    "        if acc_passed_pitch:\n",
    "            if pitch != acc_passed_pitch[-1]:\n",
    "                relative_pitch = pitch - acc_passed_pitch[-1]\n",
    "                pitch_pattern_acc.append(relative_pitch)\n",
    "                rythm_pattern_acc.append(1)\n",
    "            else:\n",
    "                pitch_pattern_acc.append(pitch_pattern_acc[-1])\n",
    "                rythm_pattern_acc.append(0)\n",
    "        acc_passed_pitch.append(pitch)\n",
    "    \n",
    "    # Create the pattern for melody\n",
    "    mel_passed_pitch = []\n",
    "    pitch_pattern_mel = [0]\n",
    "    \n",
    "    # Do we start with a note played or not ?\n",
    "    if melody_pitches[0] > 0:\n",
    "        rythm_pattern_mel = [1]\n",
    "    else:\n",
    "        rythm_pattern_mel = [0]\n",
    "        \n",
    "    for pitch in melody_pitches:\n",
    "        if mel_passed_pitch:\n",
    "            if pitch != mel_passed_pitch[-1]:\n",
    "                relative_pitch = pitch - mel_passed_pitch[-1]\n",
    "                pitch_pattern_mel.append(relative_pitch)\n",
    "                rythm_pattern_mel.append(1)\n",
    "            else:\n",
    "                pitch_pattern_mel.append(pitch_pattern_mel[-1])\n",
    "                rythm_pattern_mel.append(0)\n",
    "        mel_passed_pitch.append(pitch)\n",
    "\n",
    "    return {\n",
    "        'rythm_pattern':{'acc':rythm_pattern_mel,'mel':rythm_pattern_mel},\n",
    "        'pitch_pattern':{'acc':pitch_pattern_mel,'mel':pitch_pattern_mel}\n",
    "           }    \n",
    "    \n",
    "def custom_metric(accompaniment, predicted_melody, weight=1):\n",
    "    \"\"\"\n",
    "    TODO : Doc string\n",
    "    \"\"\"\n",
    "    # Get the pitch and rythm pattern for both accompaniment and melody\n",
    "    patterns = pattern_recognition(accompaniment, predicted_melody)\n",
    "    pitch_pattern_acc = patterns['pitch_pattern']['acc']\n",
    "    pitch_pattern_mel = patterns['pitch_pattern']['mel']\n",
    "    rythm_pattern_acc = patterns['rythm_pattern']['acc']\n",
    "    rythm_pattern_mel = patterns['rythm_pattern']['mel']\n",
    "    \n",
    "    # Compute the mean of velocities for both accompaniment and melody\n",
    "    list_mean_vel_acc = [\n",
    "        np.mean(\n",
    "            [vel for vel in frame if vel > 0]\n",
    "        )\n",
    "        for frame in accompaniment.T\n",
    "        if np.sum(frame) > 0]\n",
    "    \n",
    "    # Check if the list is empty\n",
    "    if not list_mean_vel_acc:\n",
    "        list_mean_vel_acc = [0]\n",
    "    \n",
    "    mean_vel_acc = np.mean(list_mean_vel_acc)\n",
    "    \n",
    "    list_mean_vel_pred = [pred for pred in predicted_melody[500:] if pred > 0]\n",
    "    \n",
    "    # Check if the list is empty\n",
    "    if not list_mean_vel_pred:\n",
    "        list_mean_vel_pred = [0]\n",
    "        \n",
    "    mean_vel_pred = np.mean(list_mean_vel_pred)\n",
    "    \n",
    "    # Compute the diff beetween the two velocities mean\n",
    "    velocity_diff = abs(mean_vel_acc - mean_vel_pred)\n",
    "    \n",
    "    # Compute the \"diff pattern\" beetween accompaniment and melody\n",
    "    diff_pitch_pattern = np.array([abs(acc - mel) for acc, mel in zip(pitch_pattern_acc, pitch_pattern_mel)]).reshape(-1, 1)\n",
    "    \n",
    "    # Compute the entropy of the diff pattern\n",
    "    if np.sum(diff_pitch_pattern) == 0:\n",
    "        pitch_entropy_score = 0\n",
    "    else:\n",
    "        pitch_entropy_score = entropy(diff_pitch_pattern)[0]\n",
    "        \n",
    "    # Now we do the same for rythm pattern\n",
    "    diff_rythm_pattern = np.array([acc + mel for acc, mel in zip(rythm_pattern_acc, rythm_pattern_mel)]).reshape(-1, 1)\n",
    "        \n",
    "    # Compute the entropy of the diff pattern\n",
    "    if np.sum(diff_rythm_pattern) == 0:\n",
    "        rythm_entropy_score = 0\n",
    "    else:\n",
    "        rythm_entropy_score = entropy(diff_rythm_pattern)[0]\n",
    "        \n",
    "    # Compute the \"note's length score\" of the melody\n",
    "    notes_length_score = rythm_pattern_mel.count(1) * weight\n",
    "    \n",
    "    # Compute the final score\n",
    "    entropy_score = pitch_entropy_score + rythm_entropy_score\n",
    "\n",
    "    return np.mean([entropy_score, velocity_diff, notes_length_score])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fa89d6-6baf-4724-bb6b-3b072470e2b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Compute the score within a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd36444f-e22e-4242-9f8b-7197b561593f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'criterion':               [\"squared_error\",\"friedman_mse\",\"absolute_error\",\"poisson\"],\n",
    "    'max_depth':               [None, 2, 12, 128],\n",
    "    'min_samples_split':       [2, 3, 5, 10],\n",
    "    'min_samples_leaf':        [1, 2, 3, 4],\n",
    "    'min_weight_fraction_leaf':[0.0, 0.2, 0.4, 0.5],\n",
    "    'max_leaf_nodes':          [None, 128, 12, 2],\n",
    "    'min_impurity_decrease':   [0.0, 0.2, 0.5, 0.8],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca9b257-1249-457b-9888-88b983957ff8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e65aeb3-1833-4d19-b633-70f72407af56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': {'criterion': 'friedman_mse',\n",
       "  'max_depth': 128,\n",
       "  'min_samples_split': 2,\n",
       "  'min_samples_leaf': 1,\n",
       "  'min_weight_fraction_leaf': 0.0,\n",
       "  'max_leaf_nodes': 128,\n",
       "  'min_impurity_decrease': 0.2},\n",
       " 'score': 6.957092800922064}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First grid search best params\n",
    "\n",
    "{'params': {'criterion': 'friedman_mse',\n",
    "  'max_depth': 128,\n",
    "  'min_samples_split': 2},\n",
    " 'score': 8.528335277288813}\n",
    "\n",
    "# Second grid search best params\n",
    "\n",
    "{'params': {'criterion': 'friedman_mse',\n",
    "  'max_depth': 128,\n",
    "  'min_samples_split': 2,\n",
    "  'min_samples_leaf': 1,\n",
    "  'min_weight_fraction_leaf': 0.0,\n",
    "  'max_leaf_nodes': 128},\n",
    " 'score': 9.93505034874958}\n",
    "\n",
    "# Last grid search best params\n",
    "\n",
    "{'params': {'criterion': 'friedman_mse',\n",
    "  'max_depth': 128,\n",
    "  'min_samples_split': 2,\n",
    "  'min_samples_leaf': 1,\n",
    "  'min_weight_fraction_leaf': 0.0,\n",
    "  'max_leaf_nodes': 128,\n",
    "  'min_impurity_decrease': 0.2},\n",
    " 'score': 6.957092800922064}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "510a09de-b63b-4110-8305-71a269bae6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': {'criterion': 'friedman_mse',\n",
       "  'max_depth': 128,\n",
       "  'min_samples_split': 2},\n",
       " 'score': 6.755850017125949}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'params': {'criterion': 'friedman_mse',\n",
    "  'max_depth': 128,\n",
    "  'min_samples_split': 2},\n",
    " 'score': 6.755850017125949}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f45a401f-8356-4ebd-bf79-8ce7db5b0dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{\n",
    "    'criterion':crit,\n",
    "           'max_depth':128,\n",
    "           'min_samples_split':2,\n",
    "           'min_samples_leaf':1,\n",
    "           'min_weight_fraction_leaf':0.0,\n",
    "           'max_leaf_nodes':128,\n",
    "           'min_impurity_decrease':0.5\n",
    "}\n",
    "          for crit in grid['criterion']\n",
    "          # for max_d in grid['max_depth']\n",
    "          # for min_ss in grid['min_samples_split']\n",
    "          # # for min_sl in grid['min_samples_leaf']\n",
    "          # # for min_w in grid['min_weight_fraction_leaf']\n",
    "          # # for max_l in grid['max_leaf_nodes']\n",
    "          # for min_i in grid['min_impurity_decrease']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "106cc366-496d-482e-9865-b81f06f1a725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f789d7fb-6a5a-41e9-9d12-1ca467b3e8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 observations\n"
     ]
    }
   ],
   "source": [
    "path = '../raw_data/pretty_midi'\n",
    "directory = [file_name for file_name in listdir(path) if getsize(f'{path}/{file_name}') < 300_000]\n",
    "\n",
    "for i, file_name in enumerate(directory):\n",
    "    file = joblib.load(f'{path}/{file_name}')\n",
    "    if i == 0:\n",
    "        X, y = create_simple_dataset(file, ratio=0.2)\n",
    "    else:\n",
    "        try:\n",
    "            loaded = create_simple_dataset(file, ratio=0.2)\n",
    "            X = np.concatenate((X, loaded[0]))\n",
    "            y = np.concatenate((y, loaded[1]))\n",
    "            del([loaded, file])\n",
    "        except:\n",
    "            pass\n",
    "    if i % 10 == 0:\n",
    "        print(f'{X.shape[0]} observations')\n",
    "    if X.shape[0] >= 0:\n",
    "        break\n",
    "\n",
    "chord = adding_chords_info('../raw_data/chords_midi.csv', X)\n",
    "\n",
    "X_reshaped = X.reshape((X.shape[0], -1))\n",
    "X_reshaped = np.concatenate((chord, X_reshaped), axis=1, dtype=np.int8)\n",
    "\n",
    "y = y.reshape((y.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e21e2aa-4624-4867-a53d-c2fa64fa1630",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 1 done\n",
      "split 2 done\n",
      "split 3 done\n",
      "split 4 done\n",
      "split 5 done\n"
     ]
    }
   ],
   "source": [
    "params_and_scores = {}\n",
    "\n",
    "for split in range(5):\n",
    "    X_train, X_test, X_reshaped_train, X_reshaped_test, y_train, y_test = train_test_split(X, X_reshaped, y, test_size=0.1)\n",
    "    params_and_scores[f'split_{split}'] = []\n",
    "    for i, param in enumerate(params):\n",
    "\n",
    "        tree = DecisionTreeRegressor(**param)\n",
    "        tree.fit(X_reshaped_train, y_train)\n",
    "        predictions = tree.predict(X_reshaped_test)\n",
    "        scores = [custom_metric(test, pred, weight=10) for test, pred in zip(X_test, predictions)]\n",
    "        score = np.mean(scores)\n",
    "        params_and_scores[f'split_{split}'].append({'params':param, 'score':score})\n",
    "    print(f'split {split+1} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58a5c9ae-9480-4b26-9646-89613abf326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for split in params_and_scores:\n",
    "    scores[split] = []\n",
    "    for param in params_and_scores[split]:\n",
    "        scores[split].append(param['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aefc1b63-273a-4b6d-bc05-af98bd2c170c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_scores = {}\n",
    "for split in scores:\n",
    "    best_scores[split] = np.min(scores[split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a03583d4-3e62-439d-b6f8-ec9e1d03b3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_per_params = {}\n",
    "\n",
    "for split in scores:\n",
    "    \n",
    "    # Create the lists\n",
    "    for index, score in enumerate(scores[split]):\n",
    "        scores_per_params[index] = []\n",
    "    \n",
    "for split in scores:\n",
    "    \n",
    "    # Fill the lists\n",
    "    for index, score in enumerate(scores[split]):\n",
    "        scores_per_params[index].append(score)\n",
    "\n",
    "mean_scores_per_params = [(key, np.mean(score)) for key, score in scores_per_params.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4a86e3e-2516-44f7-ab9f-fa365bf17b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_score = np.min([s[1] for s in mean_scores_per_params])\n",
    "best_params = params_and_scores['split_0'][[s[1] for s in mean_scores_per_params].index(min_score)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10fa75f5-d55a-4fcf-89a9-55e06214b7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': {'criterion': 'absolute_error',\n",
       "  'max_depth': 128,\n",
       "  'min_samples_split': 2,\n",
       "  'min_samples_leaf': 1,\n",
       "  'min_weight_fraction_leaf': 0.0,\n",
       "  'max_leaf_nodes': 128,\n",
       "  'min_impurity_decrease': 0.5},\n",
       " 'score': 58.05813945590767}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ade140-ba78-4667-b6cb-e92e14a15819",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Best params for each grid search, metrics being updated each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cad2b9f-12c9-4f07-aeac-fbf47ca70b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best params last grid search, with note's length\n",
    "\n",
    "{'params': {'criterion': 'absolute_error',\n",
    "  'max_depth': 128,\n",
    "  'min_samples_split': 2,\n",
    "  'min_samples_leaf': 1,\n",
    "  'min_weight_fraction_leaf': 0.0,\n",
    "  'max_leaf_nodes': 128,\n",
    "  'min_impurity_decrease': 0.5},\n",
    " 'score': 58.05813945590767}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecc506e1-fae0-4bd7-8a6b-0087331b6e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': {'max_depth': None,\n",
       "  'min_samples_split': 3,\n",
       "  'min_samples_leaf': 4,\n",
       "  'min_weight_fraction_leaf': 0.2,\n",
       "  'max_leaf_nodes': None},\n",
       " 'score': 11.102578913240704}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best params second grid search, without note's length\n",
    "\n",
    "best_params = {'params': {'criterion': 'friedman_mse',\n",
    "  'max_depth': None,\n",
    "  'min_samples_split': 3,\n",
    "  'min_samples_leaf': 1,\n",
    "  'min_weight_fraction_leaf': 0.0,\n",
    "  'max_leaf_nodes': 128,\n",
    "  'min_impurity_decrease': 0.8},\n",
    " 'score': 3.934009184910246}\n",
    "\n",
    "# best params first grid search\n",
    "{'params': {'max_depth': None,\n",
    "  'min_samples_split': 3,\n",
    "  'min_samples_leaf': 1,\n",
    "  'min_weight_fraction_leaf': 0.0,\n",
    "  'max_leaf_nodes': 128},\n",
    " 'score': 4.371726592684219}\n",
    "\n",
    "# worst params first grid search\n",
    "{'params': {'max_depth': None,\n",
    "  'min_samples_split': 3,\n",
    "  'min_samples_leaf': 4,\n",
    "  'min_weight_fraction_leaf': 0.2,\n",
    "  'max_leaf_nodes': None},\n",
    " 'score': 11.102578913240704}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91d716ad-b9b8-4648-bd4e-c0c6705f730f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': {'criterion': 'absolute_error',\n",
       "  'max_depth': 12,\n",
       "  'min_samples_split': 5,\n",
       "  'min_samples_leaf': 1,\n",
       "  'min_weight_fraction_leaf': 0.0,\n",
       "  'max_leaf_nodes': 12,\n",
       "  'min_impurity_decrease': 0.5},\n",
       " 'score': 3.376318707323766}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best params first grid search, without rythm pattern and note's length, without CV\n",
    "\n",
    "{'params': {'criterion': 'absolute_error',\n",
    "  'max_depth': 12,\n",
    "  'min_samples_split': 5},\n",
    " 'score': 3.9304437664246548}\n",
    "\n",
    "# Best params second grid search with CV\n",
    "\n",
    "{'params': {'criterion': 'absolute_error',\n",
    "  'max_depth': 12,\n",
    "  'min_samples_split': 5,\n",
    "  'min_samples_leaf': 1,\n",
    "  'min_weight_fraction_leaf': 0.0,\n",
    "  'max_leaf_nodes': 12},\n",
    " 'score': 2.427159698274215}\n",
    "\n",
    "# Best params last grid search with CV\n",
    "\n",
    "{'params': {'criterion': 'absolute_error',\n",
    "  'max_depth': 12,\n",
    "  'min_samples_split': 5,\n",
    "  'min_samples_leaf': 1,\n",
    "  'min_weight_fraction_leaf': 0.0,\n",
    "  'max_leaf_nodes': 12,\n",
    "  'min_impurity_decrease': 0.5},\n",
    " 'score': 3.376318707323766}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
